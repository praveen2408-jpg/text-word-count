{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "Text1=\"VAMSHIDHAR YALALA   3-4-62/1, Aravindhnagar, Ramanthapur,+91-7396173594 Uppal, Hyderabad  500039 vamshi12367@gmail.com    CAREER OBJECTIVE:  To work in an organization where I can acquire new knowledge and sharpen my skills and put my efforts for achieving organization as well as Individual goals.  ACADEMIC QUALIFICATIONS:   B.Tech, EEE, SNIST, Ghatkesar, Hyderabad (2014-2018) | Aggregate: 69.22%   Intermediate, MPC, Narayana Junior College, Tarnaka, Hyderabad (2013-2014) | Aggregate :80 %   SSC, Sri Sai School, Street no-8, Habsiguda (2000 - 2012) | Aggregate : 9.0(CGPA)   TECHNICAL SKILLS:   Programming  C, C++,Data structures.    Documentation & Presentations  Microsoft Office   PROJECTS:   Automatic Door Bell :  If we install this Automatic Door bell using Object Detection Circuit\"\n",
    "Text2=\"The circuit will  sense the presence of the person and it rings the door bell.      INTERNSHIP:   SCADA  Based Power Control Of Gas Insulated Substation (400/220KV),Dichpally,Nizamabad.  ACTIVITIES & ACHIEVEMENTS:   Founder and TreasurerNGO-SNIST), 2016-2017.   Chief Head of Walk For A Cause (Annual Fund Raising Event For Welfare of  Poor students),2017.  Co-Ordinator  Innovision 2k15 at SNIST.  Co-Ordinator for Brain O brain fest.  Organizer of Walk For A Cause (Fund Raising Event )-2015 for orphans.  Organizer of Walk For A Hope of Sreenidhi Cancer Foundation-2017 for cancer patients.   STRENGTHS:   Experience in Working under Pressure.  Agile Learner.  HOBBIES & INTERESTS:   Playing and Watching Cricket.     Watching Movies\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "129\n"
     ]
    }
   ],
   "source": [
    "words = nltk.word_tokenize(Text2)     \n",
    "print(len(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "176\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['vamshidhar',\n",
       " 'yalala',\n",
       " 'aravindhnagar',\n",
       " 'ramanthapur',\n",
       " 'uppal',\n",
       " 'hyderabad',\n",
       " 'career',\n",
       " 'objective',\n",
       " 'to',\n",
       " 'work',\n",
       " 'in',\n",
       " 'an',\n",
       " 'organization',\n",
       " 'where',\n",
       " 'i',\n",
       " 'can',\n",
       " 'acquire',\n",
       " 'new',\n",
       " 'knowledge',\n",
       " 'and',\n",
       " 'sharpen',\n",
       " 'my',\n",
       " 'skills',\n",
       " 'and',\n",
       " 'put',\n",
       " 'my',\n",
       " 'efforts',\n",
       " 'for',\n",
       " 'achieving',\n",
       " 'organization',\n",
       " 'as',\n",
       " 'well',\n",
       " 'as',\n",
       " 'individual',\n",
       " 'goals',\n",
       " 'academic',\n",
       " 'qualifications',\n",
       " 'eee',\n",
       " 'snist',\n",
       " 'ghatkesar',\n",
       " 'hyderabad',\n",
       " 'aggregate',\n",
       " 'intermediate',\n",
       " 'mpc',\n",
       " 'narayana',\n",
       " 'junior',\n",
       " 'college',\n",
       " 'tarnaka',\n",
       " 'hyderabad',\n",
       " 'aggregate',\n",
       " 'ssc',\n",
       " 'sri',\n",
       " 'sai',\n",
       " 'school',\n",
       " 'street',\n",
       " 'habsiguda',\n",
       " 'aggregate',\n",
       " 'cgpa',\n",
       " 'technical',\n",
       " 'skills',\n",
       " 'programming',\n",
       " 'c',\n",
       " 'data',\n",
       " 'structures',\n",
       " 'documentation',\n",
       " 'presentations',\n",
       " 'microsoft',\n",
       " 'office',\n",
       " 'projects',\n",
       " 'automatic',\n",
       " 'door',\n",
       " 'bell',\n",
       " 'if',\n",
       " 'we',\n",
       " 'install',\n",
       " 'this',\n",
       " 'automatic',\n",
       " 'door',\n",
       " 'bell',\n",
       " 'using',\n",
       " 'object',\n",
       " 'detection',\n",
       " 'circuit',\n",
       " 'the',\n",
       " 'circuit',\n",
       " 'will',\n",
       " 'sense',\n",
       " 'the',\n",
       " 'presence',\n",
       " 'of',\n",
       " 'the',\n",
       " 'person',\n",
       " 'and',\n",
       " 'it',\n",
       " 'rings',\n",
       " 'the',\n",
       " 'door',\n",
       " 'bell',\n",
       " 'internship',\n",
       " 'scada',\n",
       " 'based',\n",
       " 'power',\n",
       " 'control',\n",
       " 'of',\n",
       " 'gas',\n",
       " 'insulated',\n",
       " 'substation',\n",
       " 'dichpally',\n",
       " 'nizamabad',\n",
       " 'activities',\n",
       " 'achievements',\n",
       " 'founder',\n",
       " 'and',\n",
       " 'chief',\n",
       " 'head',\n",
       " 'of',\n",
       " 'walk',\n",
       " 'for',\n",
       " 'a',\n",
       " 'cause',\n",
       " 'annual',\n",
       " 'fund',\n",
       " 'raising',\n",
       " 'event',\n",
       " 'for',\n",
       " 'welfare',\n",
       " 'of',\n",
       " 'poor',\n",
       " 'students',\n",
       " 'innovision',\n",
       " 'at',\n",
       " 'snist',\n",
       " 'for',\n",
       " 'brain',\n",
       " 'o',\n",
       " 'brain',\n",
       " 'fest',\n",
       " 'organizer',\n",
       " 'of',\n",
       " 'walk',\n",
       " 'for',\n",
       " 'a',\n",
       " 'cause',\n",
       " 'fund',\n",
       " 'raising',\n",
       " 'event',\n",
       " 'for',\n",
       " 'orphans',\n",
       " 'organizer',\n",
       " 'of',\n",
       " 'walk',\n",
       " 'for',\n",
       " 'a',\n",
       " 'hope',\n",
       " 'of',\n",
       " 'sreenidhi',\n",
       " 'cancer',\n",
       " 'for',\n",
       " 'cancer',\n",
       " 'patients',\n",
       " 'strengths',\n",
       " 'experience',\n",
       " 'in',\n",
       " 'working',\n",
       " 'under',\n",
       " 'pressure',\n",
       " 'agile',\n",
       " 'learner',\n",
       " 'hobbies',\n",
       " 'interests',\n",
       " 'playing',\n",
       " 'and',\n",
       " 'watching',\n",
       " 'cricket',\n",
       " 'watching',\n",
       " 'movies']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# to remove punctutions\n",
    "words=[word.lower() for word in words if word.isalpha()]\n",
    "print(len(words))\n",
    "words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i',\n",
       " 'me',\n",
       " 'my',\n",
       " 'myself',\n",
       " 'we',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'you',\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " \"you'll\",\n",
       " \"you'd\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves',\n",
       " 'he',\n",
       " 'him',\n",
       " 'his',\n",
       " 'himself',\n",
       " 'she',\n",
       " \"she's\",\n",
       " 'her',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'it',\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'they',\n",
       " 'them',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'themselves',\n",
       " 'what',\n",
       " 'which',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'this',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'these',\n",
       " 'those',\n",
       " 'am',\n",
       " 'is',\n",
       " 'are',\n",
       " 'was',\n",
       " 'were',\n",
       " 'be',\n",
       " 'been',\n",
       " 'being',\n",
       " 'have',\n",
       " 'has',\n",
       " 'had',\n",
       " 'having',\n",
       " 'do',\n",
       " 'does',\n",
       " 'did',\n",
       " 'doing',\n",
       " 'a',\n",
       " 'an',\n",
       " 'the',\n",
       " 'and',\n",
       " 'but',\n",
       " 'if',\n",
       " 'or',\n",
       " 'because',\n",
       " 'as',\n",
       " 'until',\n",
       " 'while',\n",
       " 'of',\n",
       " 'at',\n",
       " 'by',\n",
       " 'for',\n",
       " 'with',\n",
       " 'about',\n",
       " 'against',\n",
       " 'between',\n",
       " 'into',\n",
       " 'through',\n",
       " 'during',\n",
       " 'before',\n",
       " 'after',\n",
       " 'above',\n",
       " 'below',\n",
       " 'to',\n",
       " 'from',\n",
       " 'up',\n",
       " 'down',\n",
       " 'in',\n",
       " 'out',\n",
       " 'on',\n",
       " 'off',\n",
       " 'over',\n",
       " 'under',\n",
       " 'again',\n",
       " 'further',\n",
       " 'then',\n",
       " 'once',\n",
       " 'here',\n",
       " 'there',\n",
       " 'when',\n",
       " 'where',\n",
       " 'why',\n",
       " 'how',\n",
       " 'all',\n",
       " 'any',\n",
       " 'both',\n",
       " 'each',\n",
       " 'few',\n",
       " 'more',\n",
       " 'most',\n",
       " 'other',\n",
       " 'some',\n",
       " 'such',\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'only',\n",
       " 'own',\n",
       " 'same',\n",
       " 'so',\n",
       " 'than',\n",
       " 'too',\n",
       " 'very',\n",
       " 's',\n",
       " 't',\n",
       " 'can',\n",
       " 'will',\n",
       " 'just',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'should',\n",
       " \"should've\",\n",
       " 'now',\n",
       " 'd',\n",
       " 'll',\n",
       " 'm',\n",
       " 'o',\n",
       " 're',\n",
       " 've',\n",
       " 'y',\n",
       " 'ain',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'ma',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\"]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " # Reading the stopwords from the corpus\n",
    "stop = stopwords.words('english')\n",
    "stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\maheshwaram\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130\n"
     ]
    }
   ],
   "source": [
    "# Removing the stop words from the text\n",
    "tokens= [token for token in words if token not in stop]\n",
    "tokens\n",
    "print(len(tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'vamshidhar': 1,\n",
       " 'yalala': 1,\n",
       " 'aravindhnagar': 1,\n",
       " 'ramanthapur': 1,\n",
       " 'uppal': 1,\n",
       " 'hyderabad': 3,\n",
       " 'career': 1,\n",
       " 'objective': 1,\n",
       " 'work': 1,\n",
       " 'organization': 2,\n",
       " 'acquire': 1,\n",
       " 'new': 1,\n",
       " 'knowledge': 1,\n",
       " 'sharpen': 1,\n",
       " 'skills': 2,\n",
       " 'put': 1,\n",
       " 'efforts': 1,\n",
       " 'achieving': 1,\n",
       " 'well': 1,\n",
       " 'individual': 1,\n",
       " 'goals': 1,\n",
       " 'academic': 1,\n",
       " 'qualifications': 1,\n",
       " 'eee': 1,\n",
       " 'snist': 2,\n",
       " 'ghatkesar': 1,\n",
       " 'aggregate': 3,\n",
       " 'intermediate': 1,\n",
       " 'mpc': 1,\n",
       " 'narayana': 1,\n",
       " 'junior': 1,\n",
       " 'college': 1,\n",
       " 'tarnaka': 1,\n",
       " 'ssc': 1,\n",
       " 'sri': 1,\n",
       " 'sai': 1,\n",
       " 'school': 1,\n",
       " 'street': 1,\n",
       " 'habsiguda': 1,\n",
       " 'cgpa': 1,\n",
       " 'technical': 1,\n",
       " 'programming': 1,\n",
       " 'c': 1,\n",
       " 'data': 1,\n",
       " 'structures': 1,\n",
       " 'documentation': 1,\n",
       " 'presentations': 1,\n",
       " 'microsoft': 1,\n",
       " 'office': 1,\n",
       " 'projects': 1,\n",
       " 'automatic': 2,\n",
       " 'door': 3,\n",
       " 'bell': 3,\n",
       " 'install': 1,\n",
       " 'using': 1,\n",
       " 'object': 1,\n",
       " 'detection': 1,\n",
       " 'circuit': 2,\n",
       " 'sense': 1,\n",
       " 'presence': 1,\n",
       " 'person': 1,\n",
       " 'rings': 1,\n",
       " 'internship': 1,\n",
       " 'scada': 1,\n",
       " 'based': 1,\n",
       " 'power': 1,\n",
       " 'control': 1,\n",
       " 'gas': 1,\n",
       " 'insulated': 1,\n",
       " 'substation': 1,\n",
       " 'dichpally': 1,\n",
       " 'nizamabad': 1,\n",
       " 'activities': 1,\n",
       " 'achievements': 1,\n",
       " 'founder': 1,\n",
       " 'chief': 1,\n",
       " 'head': 1,\n",
       " 'walk': 3,\n",
       " 'cause': 2,\n",
       " 'annual': 1,\n",
       " 'fund': 2,\n",
       " 'raising': 2,\n",
       " 'event': 2,\n",
       " 'welfare': 1,\n",
       " 'poor': 1,\n",
       " 'students': 1,\n",
       " 'innovision': 1,\n",
       " 'brain': 2,\n",
       " 'fest': 1,\n",
       " 'organizer': 2,\n",
       " 'orphans': 1,\n",
       " 'hope': 1,\n",
       " 'sreenidhi': 1,\n",
       " 'cancer': 2,\n",
       " 'patients': 1,\n",
       " 'strengths': 1,\n",
       " 'experience': 1,\n",
       " 'working': 1,\n",
       " 'pressure': 1,\n",
       " 'agile': 1,\n",
       " 'learner': 1,\n",
       " 'hobbies': 1,\n",
       " 'interests': 1,\n",
       " 'playing': 1,\n",
       " 'watching': 2,\n",
       " 'cricket': 1,\n",
       " 'movies': 1}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#1st method\n",
    "#wordcount\n",
    "d={}\n",
    "for word in tokens:\n",
    "    d[word]=d.get(word,0)+1\n",
    "d    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(3, 'walk'), (3, 'hyderabad'), (3, 'door'), (3, 'bell'), (3, 'aggregate'), (2, 'watching'), (2, 'snist'), (2, 'skills'), (2, 'raising'), (2, 'organizer'), (2, 'organization'), (2, 'fund'), (2, 'event'), (2, 'circuit'), (2, 'cause'), (2, 'cancer'), (2, 'brain'), (2, 'automatic'), (1, 'yalala'), (1, 'working'), (1, 'work'), (1, 'well'), (1, 'welfare'), (1, 'vamshidhar'), (1, 'using'), (1, 'uppal'), (1, 'technical'), (1, 'tarnaka'), (1, 'substation'), (1, 'students'), (1, 'structures'), (1, 'strengths'), (1, 'street'), (1, 'ssc'), (1, 'sri'), (1, 'sreenidhi'), (1, 'sharpen'), (1, 'sense'), (1, 'school'), (1, 'scada'), (1, 'sai'), (1, 'rings'), (1, 'ramanthapur'), (1, 'qualifications'), (1, 'put'), (1, 'projects'), (1, 'programming'), (1, 'pressure'), (1, 'presentations'), (1, 'presence'), (1, 'power'), (1, 'poor'), (1, 'playing'), (1, 'person'), (1, 'patients'), (1, 'orphans'), (1, 'office'), (1, 'objective'), (1, 'object'), (1, 'nizamabad'), (1, 'new'), (1, 'narayana'), (1, 'mpc'), (1, 'movies'), (1, 'microsoft'), (1, 'learner'), (1, 'knowledge'), (1, 'junior'), (1, 'internship'), (1, 'intermediate'), (1, 'interests'), (1, 'insulated'), (1, 'install'), (1, 'innovision'), (1, 'individual'), (1, 'hope'), (1, 'hobbies'), (1, 'head'), (1, 'habsiguda'), (1, 'goals'), (1, 'ghatkesar'), (1, 'gas'), (1, 'founder'), (1, 'fest'), (1, 'experience'), (1, 'efforts'), (1, 'eee'), (1, 'documentation'), (1, 'dichpally'), (1, 'detection'), (1, 'data'), (1, 'cricket'), (1, 'control'), (1, 'college'), (1, 'chief'), (1, 'cgpa'), (1, 'career'), (1, 'c'), (1, 'based'), (1, 'aravindhnagar'), (1, 'annual'), (1, 'agile'), (1, 'activities'), (1, 'acquire'), (1, 'achieving'), (1, 'achievements'), (1, 'academic')]\n"
     ]
    }
   ],
   "source": [
    "#sorting wordcount from high to low\n",
    "word_freq=[]\n",
    "for key,value in d.items():\n",
    "    word_freq.append((value,key))\n",
    "word_freq.sort(reverse=True)\n",
    "print(word_freq)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('hyderabad', 3),\n",
       " ('aggregate', 3),\n",
       " ('door', 3),\n",
       " ('bell', 3),\n",
       " ('walk', 3),\n",
       " ('organization', 2),\n",
       " ('skills', 2),\n",
       " ('snist', 2),\n",
       " ('automatic', 2),\n",
       " ('circuit', 2)]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#2nd method using nltk\n",
    "word_count = nltk.FreqDist(tokens)\n",
    "word_count.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 140)\t0.09087158463572462\n",
      "  (0, 150)\t0.09087158463572462\n",
      "  (0, 13)\t0.09087158463572462\n",
      "  (0, 28)\t0.09087158463572462\n",
      "  (0, 112)\t0.09087158463572462\n",
      "  (0, 17)\t0.09087158463572462\n",
      "  (0, 15)\t0.09087158463572462\n",
      "  (0, 137)\t0.09087158463572462\n",
      "  (0, 69)\t0.2726147539071738\n",
      "  (0, 12)\t0.09087158463572462\n",
      "  (0, 139)\t0.09087158463572462\n",
      "  (0, 63)\t0.09087158463572462\n",
      "  (0, 44)\t0.09087158463572462\n",
      "  (0, 37)\t0.09087158463572462\n",
      "  (0, 92)\t0.09087158463572462\n",
      "  (0, 134)\t0.09087158463572462\n",
      "  (0, 148)\t0.09087158463572462\n",
      "  (0, 71)\t0.06465588089770717\n",
      "  (0, 25)\t0.09087158463572462\n",
      "  (0, 96)\t0.18174316927144923\n",
      "  (0, 146)\t0.09087158463572462\n",
      "  (0, 35)\t0.09087158463572462\n",
      "  (0, 21)\t0.09087158463572462\n",
      "  (0, 88)\t0.09087158463572462\n",
      "  (0, 81)\t0.09087158463572462\n",
      "  :\t:\n",
      "  (1, 10)\t0.06943572165690438\n",
      "  (1, 30)\t0.06943572165690438\n",
      "  (1, 34)\t0.13887144331380877\n",
      "  (1, 56)\t0.06943572165690438\n",
      "  (1, 97)\t0.13887144331380877\n",
      "  (1, 4)\t0.06943572165690438\n",
      "  (1, 98)\t0.06943572165690438\n",
      "  (1, 68)\t0.06943572165690438\n",
      "  (1, 121)\t0.06943572165690438\n",
      "  (1, 36)\t0.13887144331380877\n",
      "  (1, 58)\t0.06943572165690438\n",
      "  (1, 99)\t0.06943572165690438\n",
      "  (1, 125)\t0.06943572165690438\n",
      "  (1, 55)\t0.06943572165690438\n",
      "  (1, 149)\t0.06943572165690438\n",
      "  (1, 136)\t0.06943572165690438\n",
      "  (1, 106)\t0.06943572165690438\n",
      "  (1, 24)\t0.06943572165690438\n",
      "  (1, 82)\t0.06943572165690438\n",
      "  (1, 67)\t0.06943572165690438\n",
      "  (1, 76)\t0.06943572165690438\n",
      "  (1, 101)\t0.06943572165690438\n",
      "  (1, 142)\t0.13887144331380877\n",
      "  (1, 46)\t0.06943572165690438\n",
      "  (1, 84)\t0.06943572165690438\n"
     ]
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "response = vectorizer.fit_transform([Text1,Text2])\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vamshidhar  -  0.09087158463572462\n",
      "yalala  -  0.09087158463572462\n",
      "62  -  0.09087158463572462\n",
      "aravindhnagar  -  0.09087158463572462\n",
      "ramanthapur  -  0.09087158463572462\n",
      "91  -  0.09087158463572462\n",
      "7396173594  -  0.09087158463572462\n",
      "uppal  -  0.09087158463572462\n",
      "hyderabad  -  0.2726147539071738\n",
      "500039  -  0.09087158463572462\n",
      "vamshi12367  -  0.09087158463572462\n",
      "gmail  -  0.09087158463572462\n",
      "com  -  0.09087158463572462\n",
      "career  -  0.09087158463572462\n",
      "objective  -  0.09087158463572462\n",
      "to  -  0.09087158463572462\n",
      "work  -  0.09087158463572462\n",
      "in  -  0.06465588089770717\n",
      "an  -  0.09087158463572462\n",
      "organization  -  0.18174316927144923\n",
      "where  -  0.09087158463572462\n",
      "can  -  0.09087158463572462\n",
      "acquire  -  0.09087158463572462\n",
      "new  -  0.09087158463572462\n",
      "knowledge  -  0.09087158463572462\n",
      "and  -  0.12931176179541434\n",
      "sharpen  -  0.09087158463572462\n",
      "my  -  0.18174316927144923\n",
      "skills  -  0.18174316927144923\n",
      "put  -  0.09087158463572462\n",
      "efforts  -  0.09087158463572462\n",
      "for  -  0.06465588089770717\n",
      "achieving  -  0.09087158463572462\n",
      "as  -  0.18174316927144923\n",
      "well  -  0.09087158463572462\n",
      "individual  -  0.09087158463572462\n",
      "goals  -  0.09087158463572462\n",
      "academic  -  0.09087158463572462\n",
      "qualifications  -  0.09087158463572462\n",
      "tech  -  0.09087158463572462\n",
      "eee  -  0.09087158463572462\n",
      "snist  -  0.06465588089770717\n",
      "ghatkesar  -  0.09087158463572462\n",
      "2014  -  0.18174316927144923\n",
      "2018  -  0.09087158463572462\n",
      "aggregate  -  0.2726147539071738\n",
      "69  -  0.09087158463572462\n",
      "22  -  0.09087158463572462\n",
      "intermediate  -  0.09087158463572462\n",
      "mpc  -  0.09087158463572462\n",
      "narayana  -  0.09087158463572462\n",
      "junior  -  0.09087158463572462\n",
      "college  -  0.09087158463572462\n",
      "tarnaka  -  0.09087158463572462\n",
      "2013  -  0.09087158463572462\n",
      "80  -  0.09087158463572462\n",
      "ssc  -  0.09087158463572462\n",
      "sri  -  0.09087158463572462\n",
      "sai  -  0.09087158463572462\n",
      "school  -  0.09087158463572462\n",
      "street  -  0.09087158463572462\n",
      "no  -  0.09087158463572462\n",
      "habsiguda  -  0.09087158463572462\n",
      "2000  -  0.09087158463572462\n",
      "2012  -  0.09087158463572462\n",
      "cgpa  -  0.09087158463572462\n",
      "technical  -  0.09087158463572462\n",
      "programming  -  0.09087158463572462\n",
      "data  -  0.09087158463572462\n",
      "structures  -  0.09087158463572462\n",
      "documentation  -  0.09087158463572462\n",
      "presentations  -  0.09087158463572462\n",
      "microsoft  -  0.09087158463572462\n",
      "office  -  0.09087158463572462\n",
      "projects  -  0.09087158463572462\n",
      "automatic  -  0.18174316927144923\n",
      "door  -  0.12931176179541434\n",
      "bell  -  0.12931176179541434\n",
      "if  -  0.09087158463572462\n",
      "we  -  0.09087158463572462\n",
      "install  -  0.09087158463572462\n",
      "this  -  0.09087158463572462\n",
      "using  -  0.09087158463572462\n",
      "object  -  0.09087158463572462\n",
      "detection  -  0.09087158463572462\n",
      "circuit  -  0.06465588089770717\n",
      "in  -  0.06465588089770717\n",
      "and  -  0.12931176179541434\n",
      "for  -  0.06465588089770717\n",
      "snist  -  0.06465588089770717\n",
      "door  -  0.12931176179541434\n",
      "bell  -  0.12931176179541434\n",
      "circuit  -  0.06465588089770717\n",
      "the  -  0.0\n",
      "will  -  0.0\n",
      "sense  -  0.0\n",
      "presence  -  0.0\n",
      "of  -  0.0\n",
      "person  -  0.0\n",
      "it  -  0.0\n",
      "rings  -  0.0\n",
      "internship  -  0.0\n",
      "scada  -  0.0\n",
      "based  -  0.0\n",
      "power  -  0.0\n",
      "control  -  0.0\n",
      "gas  -  0.0\n",
      "insulated  -  0.0\n",
      "substation  -  0.0\n",
      "400  -  0.0\n",
      "220kv  -  0.0\n",
      "dichpally  -  0.0\n",
      "nizamabad  -  0.0\n",
      "activities  -  0.0\n",
      "achievements  -  0.0\n",
      "founder  -  0.0\n",
      "treasurerngo  -  0.0\n",
      "2016  -  0.0\n",
      "2017  -  0.0\n",
      "chief  -  0.0\n",
      "head  -  0.0\n",
      "walk  -  0.0\n",
      "cause  -  0.0\n",
      "annual  -  0.0\n",
      "fund  -  0.0\n",
      "raising  -  0.0\n",
      "event  -  0.0\n",
      "welfare  -  0.0\n",
      "poor  -  0.0\n",
      "students  -  0.0\n",
      "co  -  0.0\n",
      "ordinator  -  0.0\n",
      "innovision  -  0.0\n",
      "2k15  -  0.0\n",
      "at  -  0.0\n",
      "brain  -  0.0\n",
      "fest  -  0.0\n",
      "organizer  -  0.0\n",
      "2015  -  0.0\n",
      "orphans  -  0.0\n",
      "hope  -  0.0\n",
      "sreenidhi  -  0.0\n",
      "cancer  -  0.0\n",
      "foundation  -  0.0\n",
      "patients  -  0.0\n",
      "strengths  -  0.0\n",
      "experience  -  0.0\n",
      "working  -  0.0\n",
      "under  -  0.0\n",
      "pressure  -  0.0\n",
      "agile  -  0.0\n",
      "learner  -  0.0\n",
      "hobbies  -  0.0\n",
      "interests  -  0.0\n",
      "playing  -  0.0\n",
      "watching  -  0.0\n",
      "cricket  -  0.0\n",
      "movies  -  0.0\n"
     ]
    }
   ],
   "source": [
    "feature_names=vectorizer.get_feature_names()\n",
    "for col in response.nonzero()[1]:\n",
    "    print (feature_names[col], ' - ', response[0, col])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "items not found",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-78-e97695dd8b31>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mA\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mvalue\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[0mA\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mA\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msort\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreverse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mA\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\anaconda\\lib\\site-packages\\scipy\\sparse\\base.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, attr)\u001b[0m\n\u001b[0;32m    687\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetnnz\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    688\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 689\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mattr\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\" not found\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    690\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    691\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mtranspose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: items not found"
     ]
    }
   ],
   "source": [
    "A=[]\n",
    "for key,value in response.items():\n",
    "    A.append((value,key))\n",
    "A.sort(reverse=True)\n",
    "print(A)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.09087158 0.09087158 0.09087158 0.18174317 0.         0.\n",
      "  0.         0.09087158 0.09087158 0.         0.         0.\n",
      "  0.09087158 0.09087158 0.09087158 0.09087158 0.09087158 0.09087158\n",
      "  0.09087158 0.         0.09087158 0.09087158 0.         0.27261475\n",
      "  0.         0.09087158 0.12931176 0.         0.09087158 0.18174317\n",
      "  0.         0.18174317 0.         0.12931176 0.         0.09087158\n",
      "  0.         0.09087158 0.         0.09087158 0.         0.06465588\n",
      "  0.         0.09087158 0.09087158 0.         0.         0.09087158\n",
      "  0.09087158 0.         0.09087158 0.12931176 0.09087158 0.09087158\n",
      "  0.         0.         0.         0.06465588 0.         0.\n",
      "  0.         0.         0.09087158 0.09087158 0.09087158 0.09087158\n",
      "  0.         0.         0.         0.27261475 0.09087158 0.06465588\n",
      "  0.09087158 0.         0.09087158 0.         0.         0.09087158\n",
      "  0.         0.         0.09087158 0.09087158 0.         0.09087158\n",
      "  0.         0.09087158 0.18174317 0.09087158 0.09087158 0.\n",
      "  0.09087158 0.09087158 0.09087158 0.         0.09087158 0.\n",
      "  0.18174317 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.09087158 0.         0.09087158\n",
      "  0.09087158 0.09087158 0.09087158 0.         0.09087158 0.\n",
      "  0.09087158 0.         0.09087158 0.         0.09087158 0.18174317\n",
      "  0.06465588 0.         0.09087158 0.09087158 0.09087158 0.\n",
      "  0.09087158 0.         0.         0.09087158 0.09087158 0.09087158\n",
      "  0.         0.09087158 0.09087158 0.         0.         0.09087158\n",
      "  0.09087158 0.09087158 0.09087158 0.         0.         0.09087158\n",
      "  0.         0.09087158 0.09087158 0.         0.09087158 0.\n",
      "  0.09087158]\n",
      " [0.         0.         0.         0.         0.06943572 0.06943572\n",
      "  0.20830716 0.         0.         0.06943572 0.06943572 0.06943572\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.06943572 0.         0.         0.06943572 0.\n",
      "  0.06943572 0.         0.14821226 0.06943572 0.         0.\n",
      "  0.06943572 0.         0.06943572 0.04940409 0.13887144 0.\n",
      "  0.13887144 0.         0.13887144 0.         0.06943572 0.04940409\n",
      "  0.13887144 0.         0.         0.06943572 0.06943572 0.\n",
      "  0.         0.06943572 0.         0.04940409 0.         0.\n",
      "  0.13887144 0.06943572 0.06943572 0.34582861 0.06943572 0.06943572\n",
      "  0.13887144 0.06943572 0.         0.         0.         0.\n",
      "  0.06943572 0.06943572 0.06943572 0.         0.         0.04940409\n",
      "  0.         0.06943572 0.         0.06943572 0.06943572 0.\n",
      "  0.06943572 0.06943572 0.         0.         0.06943572 0.\n",
      "  0.06943572 0.         0.         0.         0.         0.06943572\n",
      "  0.         0.         0.         0.48605005 0.         0.13887144\n",
      "  0.         0.13887144 0.06943572 0.06943572 0.06943572 0.06943572\n",
      "  0.06943572 0.06943572 0.06943572 0.         0.06943572 0.\n",
      "  0.         0.         0.         0.13887144 0.         0.06943572\n",
      "  0.         0.06943572 0.         0.06943572 0.         0.\n",
      "  0.09880818 0.06943572 0.         0.         0.         0.06943572\n",
      "  0.         0.06943572 0.06943572 0.         0.         0.\n",
      "  0.27774289 0.         0.         0.06943572 0.06943572 0.\n",
      "  0.         0.         0.         0.20830716 0.13887144 0.\n",
      "  0.06943572 0.         0.         0.06943572 0.         0.06943572\n",
      "  0.        ]]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>2000</th>\n",
       "      <th>2012</th>\n",
       "      <th>2013</th>\n",
       "      <th>2014</th>\n",
       "      <th>2015</th>\n",
       "      <th>2016</th>\n",
       "      <th>2017</th>\n",
       "      <th>2018</th>\n",
       "      <th>22</th>\n",
       "      <th>220kv</th>\n",
       "      <th>...</th>\n",
       "      <th>walk</th>\n",
       "      <th>watching</th>\n",
       "      <th>we</th>\n",
       "      <th>welfare</th>\n",
       "      <th>well</th>\n",
       "      <th>where</th>\n",
       "      <th>will</th>\n",
       "      <th>work</th>\n",
       "      <th>working</th>\n",
       "      <th>yalala</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.090872</td>\n",
       "      <td>0.090872</td>\n",
       "      <td>0.090872</td>\n",
       "      <td>0.181743</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.090872</td>\n",
       "      <td>0.090872</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.090872</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.090872</td>\n",
       "      <td>0.090872</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.090872</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.090872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.069436</td>\n",
       "      <td>0.069436</td>\n",
       "      <td>0.208307</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.069436</td>\n",
       "      <td>...</td>\n",
       "      <td>0.208307</td>\n",
       "      <td>0.138871</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.069436</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.069436</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.069436</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 151 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       2000      2012      2013      2014      2015      2016      2017  \\\n",
       "0  0.090872  0.090872  0.090872  0.181743  0.000000  0.000000  0.000000   \n",
       "1  0.000000  0.000000  0.000000  0.000000  0.069436  0.069436  0.208307   \n",
       "\n",
       "       2018        22     220kv  ...      walk  watching        we   welfare  \\\n",
       "0  0.090872  0.090872  0.000000  ...  0.000000  0.000000  0.090872  0.000000   \n",
       "1  0.000000  0.000000  0.069436  ...  0.208307  0.138871  0.000000  0.069436   \n",
       "\n",
       "       well     where      will      work   working    yalala  \n",
       "0  0.090872  0.090872  0.000000  0.090872  0.000000  0.090872  \n",
       "1  0.000000  0.000000  0.069436  0.000000  0.069436  0.000000  \n",
       "\n",
       "[2 rows x 151 columns]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dense = response.todense()\n",
    "dense.shape\n",
    "print(dense)\n",
    "import pandas as pd\n",
    "dataframe=pd.DataFrame(dense,columns=vectorizer.get_feature_names())\n",
    "dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
